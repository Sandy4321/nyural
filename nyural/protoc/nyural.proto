syntax = "proto2";
package nyural;

// Specifies the shape (dimensions) of a Blob.
message TensorShape {
  repeated int64 dim = 1 [packed = true];
}

message SolverParameter {
  optional string net = 1;
  optional int32 max_iter = 2;
  optional int32 data_size = 3 [default = 400000]; //move to HDF5param or MATparam as batch
  optional int32 gpu = 4 [default = 0];
  optional string source_train = 5; //move to HDF5param or MATparam
  optional string source_test = 6; //move to HDF5param or MATparam
  optional string transform_file = 7; // move to Transfrom param
  optional int32 mean_value = 8; //move to Transfrom param
  optional string snapshot_name = 9;
  optional int32 seed = 10; //set the seed of the random, by default 1234

  optional string run_desc = 20;
  optional string run_name = 21;
  optional NetParameter trn_net_param = 22;

  optional int32 numchunks = 24 [default = 20]; // move to input Layer data....(HDF5...)
  optional float decay = 25 [default = 0.95];

  optional float weightcost = 26 [default = 0.000002];

  optional int32 autodamp = 27 [default = 1];
  optional float drop = 28 [default = 0.6666667];
  optional float boost = 29 [default = 1.5];

  optional int32 rms = 30 [default = 0];
  optional string errtype = 31 [default = "L2"];
  optional float initlambda = 32 [default = 45];
  optional string mattype = 33 [default = "gn"];
  optional int32 skip = 34 [default = 0]; //no working by the moment. need to add in the way of loading files
  optional int32 hibrid = 35 [default = 1];
} 

enum Phase {
   TRAIN = 0;
   TEST = 1;
}

message NetParameter {
  optional string name = 1;
  repeated string input = 3;

  repeated TensorShape input_shape = 8;
  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.
}

message LayerParameter {
  optional string name = 1; // the layer name
  optional string type = 2; // the layer type
  repeated string bottom = 3; // the name of each bottom blob
  repeated string top = 4; // the name of each top blob
  optional Phase phase = 10;

  optional TransformationParameter transform_param = 100;

  optional AccuracyParameter accuracy_param = 102;
  optional ConcatParameter concat_param = 104;
  optional ConvolutionParameter convolution_param = 106;
  optional EltwiseParameter eltwise_param = 110;
  optional HDF5DataParameter hdf5_data_param = 112;
  optional PoolingParameter pooling_param = 121;
  optional PowerParameter power_param = 122;
  optional SigmoidParameter sigmoid_param = 124;
  optional TanHParameter tanh_param = 127;
  optional LinearParameter linear_param = 130;
  optional MATDataParameter mat_data_param = 131;
  optional RecurrentParameter recurrent_param = 132;
  optional WeigthedSoftMaxParameter wsoftmax_param = 133;
  optional SoftplusParameter softplus_param = 135;
}

message TransformationParameter {
  optional string mean_file = 4;
  // if specified can be repeated once (would substract it from all the channels)
  // or can be repeated the same number of times as channels
  // (would subtract them from the corresponding channel)
  optional float mean_value = 5;
}

message AccuracyParameter {
  // When computing accuracy, count as correct by comparing the true label to
  // the top k scoring classes.  By default, only compare to the top scoring
  // class (i.e. argmax).
  optional uint32 top_k = 1 [default = 1];

  // The "label" axis of the prediction blob, whose argmax corresponds to the
  // predicted label -- may be negative to index from the end (e.g., -1 for the
  // last axis).  For example, if axis == 1 and the predictions are
  // (N x C x H x W), the label blob is expected to contain N*H*W ground truth
  // labels with integer values in {0, 1, ..., C-1}.
  optional int32 axis = 2 [default = 1];

  // If specified, ignore instances with the given label.
  optional int32 ignore_label = 3;
}

message ConcatParameter {
  // The axis along which to concatenate -- may be negative to index from the
  // end (e.g., -1 for the last axis).  Other axes must have the
  // same dimension for all the bottom blobs.
  // By default, ConcatLayer concatenates blobs along the "channels" axis (1).
  optional int32 axis = 2 [default = 1];
}

message HDF5DataParameter {
  // Specify the data source.
  optional string source = 1;
  // Specify the batch size.
  optional uint32 batch_size = 2;
  optional uint32 num_chunks = 3;
}

message MATDataParameter {
  // Specify the data source.
  optional string source = 1;
  // Specify the batch size.
  optional uint32 batch_size = 2;
}

message ConvolutionParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 3 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 4; // The kernel size (square)
  optional uint32 kernel_h = 11; // The kernel height
  optional uint32 kernel_w = 12; // The kernel width
  optional uint32 group = 5 [default = 1]; // The group size for group conv
  optional uint32 stride = 6 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_h = 13; // The stride height
  optional uint32 stride_w = 14; // The stride width
}

message EltwiseParameter {
  enum EltwiseOp {
    PROD = 0;
    SUM = 1;
    MAX = 2;
  }
  optional EltwiseOp operation = 1 [default = SUM]; // element-wise operation
  repeated float coeff = 2; // blob-wise coefficient for SUM operation

  // Whether to use an asymptotically slower (for >2 inputs) but stabler method
  // of computing the gradient for the PROD operation. (No effect for SUM op.)
  optional bool stable_prod_grad = 3 [default = true];
}

message PoolingParameter {
  enum PoolMethod {
    MAX = 0;
    AVE = 1;
    STOCHASTIC = 2;
  }
  optional PoolMethod pool = 1 [default = MAX]; // The pooling method
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 4 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 2; // The kernel size (square)
  optional uint32 kernel_h = 5; // The kernel height
  optional uint32 kernel_w = 6; // The kernel width
  optional uint32 stride = 3 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_h = 7; // The stride height
  optional uint32 stride_w = 8; // The stride width
  // If global_pooling then it will pool over the size of the bottom by doing
  // kernel_h = bottom->height and kernel_w = bottom->width
  optional bool global_pooling = 12 [default = false];
}

message PowerParameter {
  // PowerLayer computes outputs y = (shift + scale * x) ^ power.
  optional float power = 1 [default = 1.0];
  optional float scale = 2 [default = 1.0];
  optional float shift = 3 [default = 0.0];
}

message SigmoidParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
}

message TanHParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
}

message LinearParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
}

message RecurrentParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
}

message WeigthedSoftMaxParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
}

message SoftplusParameter  {
  optional uint32 num_output = 1; // The number of outputs for the layer
}

